import streamlit as st
from app.transcription import transcribe_audio
from app.utils import query_llm

def main():
    st.set_page_config(page_title="MeetWise - AI Meeting Assistant")
    st.title("ğŸ™ï¸ MeetWise - AI Meeting Summarizer")

    audio_file = st.file_uploader("Upload your meeting audio file", type=["mp3", "wav", "m4a"])

    # Diarization toggle
    diarize = st.checkbox("Enable Speaker Diarization (Experimental)", value=False)

    preset_prompts = {
        "ğŸ“ Get Summary": "Summarize this meeting.",
        "ğŸ“Œ Key Points": "Extract key discussion points from the meeting.",
        "âœ… Action Items": "List action items discussed in this meeting.",
    }

    selected_prompt = ""

    if audio_file:
        st.success("Audio file uploaded!")

        st.subheader("Select a prompt or enter your own:")
        col1, col2, col3 = st.columns(3)
        if col1.button("ğŸ“ Get Summary"):
            selected_prompt = preset_prompts["ğŸ“ Get Summary"]
        if col2.button("ğŸ“Œ Key Points"):
            selected_prompt = preset_prompts["ğŸ“Œ Key Points"]
        if col3.button("âœ… Action Items"):
            selected_prompt = preset_prompts["âœ… Action Items"]

        custom_prompt = st.text_input("Or enter a custom prompt:")
        if custom_prompt:
            selected_prompt = custom_prompt

        if selected_prompt:
            with st.spinner("Transcribing audio..."):
                transcript = transcribe_audio(audio_file, diarize=diarize)

            with st.spinner("Generating response from LLM..."):
                response = query_llm(transcript, selected_prompt)

            st.subheader("ğŸ—’ï¸ Transcript")
            st.text_area("Transcription", value=transcript, height=300)

            st.subheader("ğŸ¤– LLM Response")
            st.text_area("Result", value=response, height=300)

# streamlit run run.py